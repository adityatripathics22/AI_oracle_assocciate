✅ Overview of Deep Learning Model Architectures
--> Feedforward Neural Networks (FNN / MLP) → Simplest neural networks; process fixed-size input → fixed-size output
--> Convolutional Neural Networks (CNN) → Designed for images/videos; automatically detect local patterns (edges, corners, textures)
--> Recurrent Neural Networks (RNN) → Handle sequential data (time-series, text, audio) with hidden states
--> Autoencoders → Unsupervised learning; used for feature extraction, dimensionality reduction, anomaly detection
--> Long Short-Term Memory (LSTM) → Specialized RNN variant for long-term dependencies
--> Generative Adversarial Networks (GANs) → Generate realistic synthetic data (images, audio, text)
--> Transformers → State-of-the-art for NLP (translation, text generation) and now vision as well

✅ What is a CNN?
--> CNN = Deep learning model designed for grid-like data (images, videos)
--> Unlike ANN, CNN processes 2D structure of images directly instead of flattening to 1D array
--> Goal → Reduce images into simpler, information-rich representations without losing critical features

✅ CNN Architecture (Layers)

Input Layer → Receives image data

Feature Extraction Layers → Repeated stacks of convolution + activation + pooling

Classification Layer → Fully connected layers + Softmax for final prediction

✅ Analogy: Robot House Inspector
Imagine a robot classifying house types →
--> Blueprint Detector (Convolution Layer) → Scans walls, floors, windows → detects edges, shapes, textures
--> Pattern Highlighter (Activation Function) → Marks important patterns → adds non-linearity for complex learning
--> Summarizer (Pooling Layer) → Reduces room details → keeps only most important features
--> House Expert (Fully Connected Layer) → Combines extracted features → predicts house type
--> Guess Maker (Softmax Layer) → Assigns probabilities → picks most likely class
--> Quality Checker (Dropout Layer) → Prevents robot from over-relying on one feature → reduces overfitting

✅ Key Components of CNN Feature Extraction
--> Convolution Layer → Uses small filters (kernels) to detect features like edges, corners, textures
--> Activation Function (e.g., ReLU) → Adds non-linearity → allows network to learn complex features
--> Pooling Layer (Max/Avg Pooling) → Reduces spatial dimensions → lowers computational cost, highlights dominant features

✅ Limitations of CNNs
--> Computationally expensive → Need powerful hardware for large datasets
--> Overfitting risk → Especially with small/imbalanced datasets
--> Black box nature → Hard to interpret internal working
--> Sensitivity to small changes → Slight pixel variations may cause unstable predictions

✅ Applications of CNNs
--> Image Classification → Cat vs Dog recognition
--> Object Detection → Drawing bounding boxes around objects (cars, pedestrians)
--> Image Segmentation → Pixel-level labeling (medical scans, self-driving cars)
--> Face Recognition → Identify & verify people by facial features
--> Medical Imaging → Tumor detection, disease diagnosis
--> Self-Driving Cars → Road sign detection, pedestrian recognition
--> Satellite & Remote Sensing → Land cover classification, environmental monitoring

✅ In Summary
--> CNNs are designed for images & videos, preserving 2D structure
--> Feature extraction layers (convolution, activation, pooling) automatically learn patterns
--> Classification layers make predictions
--> CNNs are powerful but require large data + computational resources
--> Widely applied in vision tasks → from image recognition to medical and satellite analysis